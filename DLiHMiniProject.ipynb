{"cells":[{"cell_type":"markdown","metadata":{"id":"uvKq4JtCynM5"},"source":["# Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"XH3bcrpby28i"},"source":["Mount the drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38746,"status":"ok","timestamp":1679648858065,"user":{"displayName":"Ab F","userId":"10662768669440018821"},"user_tz":0},"id":"e8v6i3W1y5le","outputId":"ea3bcae2-1c05-4c74-b0d9-6e23b24ee41d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"fu5IPYoOzB4C"},"source":["Import libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16525,"status":"ok","timestamp":1679648874587,"user":{"displayName":"Ab F","userId":"10662768669440018821"},"user_tz":0},"id":"Uo8eGDs8zEdK","outputId":"6c11f3e2-775b-4edf-d067-7bda35e77df1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchio\n","  Downloading torchio-0.18.90-py2.py3-none-any.whl (172 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.7/172.7 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer[all] in /usr/local/lib/python3.9/dist-packages (from torchio) (0.7.0)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.9/dist-packages (from torchio) (3.0.2)\n","Collecting SimpleITK!=2.0.*,!=2.1.1.1\n","  Downloading SimpleITK-2.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Deprecated\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.9/dist-packages (from torchio) (4.6.0)\n","Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.9/dist-packages (from torchio) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchio) (4.65.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torchio) (1.10.1)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.9/dist-packages (from torchio) (1.22.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.1->torchio) (4.5.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from Deprecated->torchio) (1.15.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer[all]->torchio) (8.1.3)\n","Collecting colorama<0.5.0,>=0.4.3\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting shellingham<2.0.0,>=1.3.0\n","  Downloading shellingham-1.5.0.post1-py2.py3-none-any.whl (9.4 kB)\n","Collecting rich<13.0.0,>=10.11.0\n","  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<13.0.0,>=10.11.0->typer[all]->torchio) (2.6.1)\n","Installing collected packages: SimpleITK, commonmark, shellingham, rich, Deprecated, colorama, torchio\n","Successfully installed Deprecated-1.2.13 SimpleITK-2.2.1 colorama-0.4.6 commonmark-0.9.1 rich-12.6.0 shellingham-1.5.0.post1 torchio-0.18.90\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from mpl_toolkits import mplot3d\n","import warnings\n","warnings.filterwarnings(action='ignore', category=FutureWarning)\n","import torch \n","import torch.nn as nn\n","import time\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from collections import OrderedDict\n","from torch.utils.data import Dataset, DataLoader\n","import pickle\n","\n","!pip install torchio\n","import torchio as tio\n","\n","device='cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1679648874587,"user":{"displayName":"Ab F","userId":"10662768669440018821"},"user_tz":0},"id":"7W8bfveqwpdF","outputId":"17c8e317-b442-4e03-ee30-62683b46e6fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["print(device)"]},{"cell_type":"markdown","metadata":{"id":"GqGnIGSEzSIL"},"source":["Load Data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OI7QJWoUzTrR","executionInfo":{"status":"ok","timestamp":1679648975879,"user_tz":0,"elapsed":101297,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["X_Guys=np.load('/content/drive/MyDrive/healthcare data/X_Guys.npy')\n","X_HH=np.load('/content/drive/MyDrive/healthcare data/X_HH.npy')\n","X_IOP=np.load('/content/drive/MyDrive/healthcare data/X_IOP.npy')\n","\n","y_Guys=np.load('/content/drive/MyDrive/healthcare data/y_Guys.npy')\n","y_HH=np.load('/content/drive/MyDrive/healthcare data/y_HH.npy')\n","y_IOP=np.load('/content/drive/MyDrive/healthcare data/y_IOP.npy')"]},{"cell_type":"markdown","metadata":{"id":"zl4th8J105Z7"},"source":["Split into training, and testing sets"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"d6V5xJE21Anq","executionInfo":{"status":"ok","timestamp":1679648979526,"user_tz":0,"elapsed":3652,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["training_prop=0.8\n","\n","#Randomly shuffle the sets\n","\n","np.random.seed(2718281828)\n","permutation_Guys=np.random.permutation(len(y_Guys))\n","permutation_HH=np.random.permutation(len(y_HH))\n","permutation_IOP=np.random.permutation(len(y_IOP))\n","\n","X_Guys=X_Guys[permutation_Guys]\n","X_HH=X_HH[permutation_HH]\n","X_IOP=X_IOP[permutation_IOP]\n","\n","y_Guys=y_Guys[permutation_Guys]\n","y_HH=y_HH[permutation_HH]\n","y_IOP=y_IOP[permutation_IOP]\n","\n","#Take subsets so that there are 100 images with an equal number from each source\n","\n","n=33\n","\n","X_Guys=X_Guys[:n+1]\n","X_HH=X_HH[:n]\n","X_IOP=X_IOP[:n]\n","\n","y_Guys=y_Guys[:n+1]\n","y_HH=y_HH[:n]\n","y_IOP=y_IOP[:n]\n","\n","#Separate into training and test\n","\n","X_train=[X[:int(len(X)*training_prop**2)] for X in [X_Guys,X_HH,X_IOP]]\n","y_train=[y[:int(len(y)*training_prop**2)] for y in [y_Guys,y_HH,y_IOP]]\n","\n","X_val=[X[int(len(X)*training_prop**2):int(len(X)*training_prop)] for X in [X_Guys,X_HH,X_IOP]]\n","y_val=[y[int(len(y)*training_prop**2):int(len(y)*training_prop)] for y in [y_Guys,y_HH,y_IOP]]\n","\n","X_test=[X[int(len(X)*training_prop):] for X in [X_Guys,X_HH,X_IOP]]\n","y_test=[y[int(len(y)*training_prop):] for y in [y_Guys,y_HH,y_IOP]]"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"w5XdVw_UU6dd","executionInfo":{"status":"ok","timestamp":1679648979527,"user_tz":0,"elapsed":10,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["del X_Guys\n","del X_HH\n","del X_IOP\n","del y_Guys\n","del y_HH\n","del y_IOP"]},{"cell_type":"markdown","metadata":{"id":"tbb_b5ThzUDS"},"source":["# Data Pre-Processing"]},{"cell_type":"markdown","metadata":{"id":"FW_IxvK3zkd7"},"source":["Centre the data separately for each source (to handle the different intensities generated by the different machines) and reshape to the pytorch convention \\begin{equation}Num Samples\\times Num Channels \\times Height\\times Width \\times Depth\n","\\end{equation}"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lm-9U0Cu0dyc","executionInfo":{"status":"ok","timestamp":1679648980668,"user_tz":0,"elapsed":1149,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def centring(X):\n","    epsilon = 1e-7 # To prevent division by 0\n","    mean=np.mean(X)\n","    std=np.std(X)+epsilon\n","    X=(X-mean)/std\n","    return X\n","\n","X_train=np.concatenate([centring(X) for X in X_train])\n","X_val=np.concatenate([centring(X) for X in X_val])\n","X_test=np.concatenate([centring(X) for X in X_test])\n","\n","X_train=X_train.reshape((len(X_train),1,40,128,128))\n","X_val=X_val.reshape((len(X_val),1,40,128,128))\n","X_test=X_test.reshape((len(X_test),1,40,128,128))"]},{"cell_type":"markdown","metadata":{"id":"QQbZwjyE6YuC"},"source":["Reshape the labels"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"VHyN18M66cnn","executionInfo":{"status":"ok","timestamp":1679648981718,"user_tz":0,"elapsed":1052,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["y_train=np.concatenate(y_train)\n","y_val=np.concatenate(y_val)\n","y_test=np.concatenate(y_test)\n","\n","y_train = np.concatenate(y_train).reshape(len(y_train),1,40,128,128)\n","y_val = np.concatenate(y_val).reshape(len(y_val),1,40,128,128)\n","y_test = np.concatenate(y_test).reshape(len(y_test),1,40,128,128)"]},{"cell_type":"markdown","metadata":{"id":"wBNKDPvVeOki"},"source":["Define the random data augmentation transformation"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xgL11aZNeVHJ","executionInfo":{"status":"ok","timestamp":1679648981719,"user_tz":0,"elapsed":21,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["transform=tio.Compose([tio.RandomBiasField(coefficients=0.1),tio.RandomBlur(std=1),tio.RandomNoise(),tio.RandomGamma()])"]},{"cell_type":"markdown","metadata":{"id":"C68f4li2uHl9"},"source":["Define a dataset and create the data loaders"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"YixvdxoZ7vEp","executionInfo":{"status":"ok","timestamp":1679648981719,"user_tz":0,"elapsed":21,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class base_dataset(Dataset):\n","    def __init__(self, data,target):\n","        self.data = torch.Tensor(data)\n","        self.target = torch.Tensor(target)\n","\n","    def __getitem__(self, index):\n","        x = transform(self.data[index]).to(device)\n","        y = self.target[index].to(device)\n","        return x, y\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","train_dataset = base_dataset(X_train,y_train)\n","val_dataset = base_dataset(X_val,y_val)\n","test_dataset = base_dataset(X_test,y_test)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"aPG0Xu1Hozrm","executionInfo":{"status":"ok","timestamp":1679648981719,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def id(x):\n","    return x.repeat(1,2,1,1,1)\n","\n","class discriminator_dataset(Dataset):\n","    def __init__(self,data,segmentation_target,segmentation_model=id):\n","        self.data=torch.Tensor(data)\n","        self.segmentation_target=torch.Tensor(segmentation_target)\n","        self.segmentation_model=segmentation_model\n","\n","    def __getitem__(self,index):\n","        X=transform(self.data[index]).to(device)\n","        segmentation_target=self.segmentation_target[index].to(device)\n","        true=torch.cat((X,segmentation_target),0)\n","        segmentation_pred=self.segmentation_model(X.unsqueeze(0))[0]\n","        false=torch.cat((X,segmentation_pred),0)\n","        return true,false\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def set_model(self,model):\n","        self.segmentation_model=model\n","\n","class DiscriminatorDataLoader(DataLoader):\n","    def set_model(self,model):\n","        self.dataset.set_model(model)\n","\n","train_discriminator_dataset = discriminator_dataset(X_train,y_train)\n","\n","train_discriminator_dataloader = DiscriminatorDataLoader(train_discriminator_dataset, batch_size=8, shuffle=True, drop_last=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"WAC1gknHxWgN","executionInfo":{"status":"ok","timestamp":1679648981720,"user_tz":0,"elapsed":21,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["del X_train\n","del X_val\n","del X_test\n","del y_train\n","del y_val\n","del y_test"]},{"cell_type":"markdown","metadata":{"id":"PVy6moDS7n1Z"},"source":["# Slice-wise model"]},{"cell_type":"markdown","metadata":{"id":"CBU2dgSpbUJE"},"source":["Below is various transformation functions used to convert a list of mri images to a list of slices in each of the axial, sagittal and coronal planes"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"DL1QL52pWHpZ","executionInfo":{"status":"ok","timestamp":1679648981720,"user_tz":0,"elapsed":21,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def to_sagittal(x):\n","    n,c,h,w,d=x.shape\n","    return torch.stack([x[i,:,j,:,:] for i in range(n) for j in range(h)]),n\n","\n","def from_sagittal(x,n):\n","    if x.dim()==4:\n","        t,c,w,d=x.shape\n","        h=t//n\n","        return torch.stack([torch.stack([x[j*h+i,:,:,:] for i in range(h)],1) for j in range(n)])\n","    else:\n","        t,c=x.shape\n","        h=t//n\n","        return torch.stack([torch.stack([x[j*h+i,:] for i in range(h)]).mean(0) for j in range(n)])\n","\n","def to_axial(x):\n","    n,c,h,w,d=x.shape\n","    return torch.stack([x[i,:,:,:,j] for i in range(n) for j in range(d)]),n\n","\n","def from_axial(x,n):\n","    if x.dim()==4:\n","        t,c,h,w=x.shape\n","        d=t//n\n","        return torch.stack([torch.stack([x[j*d+i,:,:,:] for i in range(d)],3) for j in range(n)])\n","    else:\n","        t,c=x.shape\n","        d=t//n\n","        return torch.stack([torch.stack([x[j*d+i,:] for i in range(d)]).mean(0) for j in range(n)])\n","\n","def to_coronal(x):\n","    n,c,h,w,d=x.shape\n","    return torch.stack([x[i,:,:,j,:] for i in range(n) for j in range(w)]),n\n","\n","def from_coronal(x,n):\n","    if x.dim()==4:\n","        t,c,h,d=x.shape\n","        w=t//n\n","        return torch.stack([torch.stack([x[j*w+i,:,:,:] for i in range(w)],2) for j in range(n)])\n","    else:\n","        t,c=x.shape\n","        w=t//n\n","        return torch.stack([torch.stack([x[j*w+i,:] for i in range(w)]).mean(0) for j in range(n)])"]},{"cell_type":"markdown","metadata":{"id":"84ufQtzQbiH9"},"source":["This is code to allow a model to be run slicewise over mri images along slices in each of the axial, sagittal and cornal planes and return the average result of these"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"nVaG87anbza1","executionInfo":{"status":"ok","timestamp":1679648981720,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["from copy import deepcopy as copy\n","\n","class SliceWiseModel(nn.Module):\n","    def __init__(self,axial_model,sagittal_model,coronal_model):\n","        super(SliceWiseModel,self).__init__()\n","        self.axial_model=axial_model\n","        self.sagittal_model=sagittal_model\n","        self.coronal_model=coronal_model\n","\n","    def forward(self,x):\n","        axial,n=to_axial(x)\n","        axial_result=from_axial(self.axial_model(axial),n)\n","        sagittal,n=to_sagittal(x)\n","        sagittal_result=from_sagittal(self.sagittal_model(sagittal),n)\n","        coronal,n=to_coronal(x)\n","        coronal_result=from_coronal(self.coronal_model(coronal),n)\n","        return (axial_result+sagittal_result+coronal_result)/3\n","\n","    @classmethod\n","    def same_model(cls,model):\n","        return SliceWiseModel(model,copy(model),copy(model))"]},{"cell_type":"markdown","metadata":{"id":"8TT6ut4AtK5B"},"source":["# Segmentation Models"]},{"cell_type":"markdown","metadata":{"id":"DVk77ffdtPB7"},"source":["This is an architecture based on UNet but is shallower and with fewer features"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"nxwWn-hZ7tyj","executionInfo":{"status":"ok","timestamp":1679648981720,"user_tz":0,"elapsed":19,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, in_channels=1, init_features=4, out_channels=1,dropout_rate=0):\n","        super(UNet, self).__init__()\n","\n","        features = init_features\n","        self.encoder1 = UNet._block(in_channels,features,\"conv1\",dropout_rate=dropout_rate)\n","        self.pool1 = nn.MaxPool2d(2)\n","        self.encoder2 = UNet._block(features,2*features,\"conv2\",dropout_rate=dropout_rate)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.bottleneck = UNet._block(2*features,4*features,\"conv3\",dropout_rate=dropout_rate)\n","        self.upconv2 = nn.ConvTranspose2d(4*features,4*features,2,stride=2)\n","        self.decoder2 = UNet._block(6*features,2*features,\"conv4\",dropout_rate=dropout_rate)\n","        self.upconv1 = nn.ConvTranspose2d(2*features,2*features,2,stride=2)\n","        self.decoder1 = UNet._block(3*features,features,\"conv5\",dropout_rate=dropout_rate)\n","        self.conv = nn.Conv2d(features,out_channels,1)\n","        self.activation=nn.Sigmoid()\n","\n","    def forward(self, x):\n","        res1=self.encoder1(x)\n","        res2=self.encoder2(self.pool1(res1))\n","        res3=self.bottleneck(self.pool2(res2))\n","\n","        temp1=self.upconv2(res3)\n","        res4=self.decoder2(torch.cat((temp1,res2),dim=1))\n","        \n","        temp2=self.upconv1(res4)\n","        res5=self.decoder1(torch.cat((temp2,res1),dim=1))\n","\n","        return self.activation(self.conv(res5))\n","\n","    @staticmethod\n","    def _block(in_channels, features, name,dropout_rate=0):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [(name,nn.Conv2d(in_channels,features,3,padding=1)),\n","                 ('dropout',nn.Dropout(dropout_rate)),\n","                 (\"relu\",nn.ReLU()),\n","                 (\"batchnorm\",nn.BatchNorm2d(features))\n","                ]))"]},{"cell_type":"markdown","metadata":{"id":"_09JPiLYtbfD"},"source":["This is the same as the above UNet model without the residual connections"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"O-dehW9izFPU","executionInfo":{"status":"ok","timestamp":1679648981721,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class CDNN(nn.Module):\n","    def __init__(self, in_channels=1, init_features=4, out_channels=1,dropout_rate=0):\n","        super(CDNN, self).__init__()\n","\n","        features = init_features\n","        self.encoder1 = CDNN._block(in_channels,features,\"conv1\",dropout_rate=dropout_rate)\n","        self.pool1 = nn.MaxPool2d(2)\n","        self.encoder2 = CDNN._block(features,2*features,\"conv2\",dropout_rate=dropout_rate)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.bottleneck = CDNN._block(2*features,4*features,\"conv3\",dropout_rate=dropout_rate)\n","        self.upconv2 = nn.ConvTranspose2d(4*features,4*features,2,stride=2)\n","        self.decoder2 = CDNN._block(4*features,2*features,\"conv4\",dropout_rate=dropout_rate)\n","        self.upconv1 = nn.ConvTranspose2d(2*features,2*features,2,stride=2)\n","        self.decoder1 = CDNN._block(2*features,features,\"conv5\",dropout_rate=dropout_rate)\n","        self.conv = nn.Conv2d(features,out_channels,1)\n","        self.activation=nn.Sigmoid()\n","\n","    def forward(self, x):\n","        res=self.encoder1(x)\n","        res=self.encoder2(self.pool1(res))\n","        res=self.bottleneck(self.pool2(res))\n","\n","        res=self.upconv2(res)\n","        res=self.decoder2(res)\n","        \n","        res=self.upconv1(res)\n","        res=self.decoder1(res)\n","\n","        return self.activation(self.conv(res))\n","\n","    @staticmethod\n","    def _block(in_channels, features, name,dropout_rate=0):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [(name,nn.Conv2d(in_channels,features,3,padding=1)),\n","                 ('dropout',nn.Dropout(dropout_rate)),\n","                 (\"relu\",nn.ReLU()),\n","                 (\"batchnorm\",nn.BatchNorm2d(features))\n","                ]))"]},{"cell_type":"markdown","metadata":{"id":"Wdr1fiiFtnCj"},"source":["This is an architecture based on VNet but altered to be 2D, shallower and with fewer features."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"kSBIzxuevbAD","executionInfo":{"status":"ok","timestamp":1679648981721,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class VNet(nn.Module):\n","\n","    def __init__(self,in_channels=1,init_features=4,out_channels=1,dropout_rate=0):\n","        super(VNet,self).__init__()\n","        features=init_features\n","        self.features=features\n","\n","        self.encoder1=VNet._convblock(in_channels,features,1,dropout_rate=dropout_rate)\n","        self.downconv1=VNet._downconvblock(features)\n","        self.encoder2=VNet._convblock(2*features,2*features,2,dropout_rate=dropout_rate)\n","        self.downconv2=VNet._downconvblock(2*features)\n","        self.encoder3=VNet._convblock(4*features,4*features,3,dropout_rate=dropout_rate)\n","        self.upconv1=VNet._upconvblock(2*features)\n","        self.decoder1=VNet._convblock(4*features,2*features,2,dropout_rate=dropout_rate)\n","        self.upconv2=VNet._upconvblock(features)\n","        self.decoder2=VNet._convblock(2*features,features,1,dropout_rate=dropout_rate)\n","        self.conv=nn.Conv2d(features,out_channels,1)\n","        self.activation=nn.Sigmoid()\n","\n","    def forward(self,x):\n","        res1=self.encoder1(x)+x.repeat(1,self.features,1,1)\n","        temp=self.downconv1(res1)\n","        res2=self.encoder2(temp)+temp\n","        temp=self.downconv2(res2)\n","        temp=self.encoder3(temp)+temp\n","        temp=self.upconv1(temp)\n","        temp=self.decoder1(torch.cat((temp,res2),dim=1))+temp\n","        temp=self.upconv2(temp)\n","        temp=self.decoder2(torch.cat((temp,res1),dim=1))+temp\n","        return self.activation(self.conv(temp))\n","\n","    @staticmethod\n","    def _conv(in_channels, features, name='conv',dropout_rate=0):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [(name,nn.Conv2d(in_channels,features,5,padding=2)),\n","                 ('dropout',nn.Dropout(dropout_rate)),\n","                 (\"prelu\",nn.PReLU()),\n","                 (\"batchnorm\",nn.BatchNorm2d(features))\n","                ]))\n","    def _convblock(in_channels,features,num_conv,name='conv',dropout_rate=0):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [(name+str(0),VNet._conv(in_channels,features,dropout_rate=dropout_rate))]\n","                +[(name+str(i),VNet._conv(features,features,dropout_rate=dropout_rate)) for i in range(1,num_conv)]\n","                ))\n","    def _downconvblock(features,name='downconv'):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [(name,nn.Conv2d(features,2*features,2,stride=2))]\n","                +[(\"prelu\",nn.PReLU())]\n","                ))\n","    def _upconvblock(features,name='upconv'):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [(name,nn.ConvTranspose2d(2*features,features,2,stride=2))]\n","                +[(\"prelu\",nn.PReLU())]\n","                ))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"1YZRf0wa0peT","executionInfo":{"status":"ok","timestamp":1679648981721,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["segmentation_models={\n","    'CDNN':CDNN,\n","    'UNet':UNet,\n","    'VNet':VNet\n","}"]},{"cell_type":"markdown","metadata":{"id":"UEdXAW-U78Gt"},"source":["# Discriminators"]},{"cell_type":"markdown","metadata":{"id":"zHmTI0hO8Egk"},"source":["This a standard feed forward network"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"xaCTkMWA8J_8","executionInfo":{"status":"ok","timestamp":1679648981722,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class ANN(nn.Module):\n","\n","  def __init__(self,input_dim,hidden_dims,out_dim=1,act=nn.ReLU(),end=nn.Sigmoid(),dropout_rate=0.5):\n","    super(ANN,self).__init__()\n","    layers=[]\n","    in_dim=input_dim\n","    for x in hidden_dims:\n","      layers.append(nn.Linear(in_dim,x))\n","      nn.init.xavier_uniform_(layers[-1].weight)\n","      layers.append(nn.Dropout(dropout_rate))\n","      in_dim=x\n","    layers.append(nn.Linear(in_dim,out_dim))\n","    layers[-1].weight.data.fill_(0)\n","    layers[-1].bias.data.fill_(0)\n","    self.layers=nn.ModuleList(layers)\n","    self.act=act\n","    self.end=end\n","\n","  def forward(self,x):\n","    x=x.flatten(1)\n","    for layer in self.layers[:-1]:\n","      x=self.act(layer(x))\n","    return self.end(self.layers[-1](x))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"1_jX-4QP9pM1","executionInfo":{"status":"ok","timestamp":1679648981722,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def ANNDiscriminator(hidden_dims=[1000,500,250],dropout_rate=0.5):\n","    c=2\n","    h=40\n","    w=128\n","    d=128\n","    axial_model=ANN(c*h*w,hidden_dims,dropout_rate=dropout_rate)\n","    sagittal_model=ANN(c*w*d,hidden_dims,dropout_rate=dropout_rate)\n","    coronal_model=ANN(c*h*d,hidden_dims,dropout_rate=dropout_rate)\n","    return SliceWiseModel(axial_model,sagittal_model,coronal_model)"]},{"cell_type":"markdown","metadata":{"id":"y_Q0h93c8KI8"},"source":["This is a CNN"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"tWyWVAHo8SHc","executionInfo":{"status":"ok","timestamp":1679648981722,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self,input_dim,in_channels=2, init_features=4,out_channels=1,fc_hidden_dims=[120,16],dropout_rate=0):\n","        super(CNN, self).__init__()\n","        # Convolutional layers\n","        features = init_features\n","        self.encoder1 = CNN._block(in_channels, features, name=\"conv1\",dropout_rate=dropout_rate)\n","        self.pool1 = nn.MaxPool2d(2, stride=2)\n","        self.encoder2 = CNN._block(features, 2*features, name=\"conv2\",dropout_rate=dropout_rate)\n","        self.pool2 = nn.MaxPool2d(2, stride=2)\n","        self.encoder3 = CNN._block(2*features, 4*features, name=\"conv3\",dropout_rate=dropout_rate)\n","\n","        # Fully connected layers\n","        self.fc = ANN(int(input_dim/16)*4*features,fc_hidden_dims,out_channels,dropout_rate=0.2)\n","\n","    def forward(self, x):\n","        temp = self.encoder1(x)\n","        temp = self.encoder2(self.pool1(temp))\n","        temp = self.encoder3(self.pool2(temp))\n","        pred = self.fc(temp)\n","        return pred\n","\n","    @staticmethod\n","    def _block(in_channels, features, name,dropout_rate=0):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [(name,nn.Conv2d(in_channels,features,3,padding=1)),\n","                 ('dropout',nn.Dropout(dropout_rate)),\n","                 (\"relu\",nn.ReLU()),\n","                 (\"batchnorm\",nn.BatchNorm2d(features))\n","                ]))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"is5WXi_8-40c","executionInfo":{"status":"ok","timestamp":1679648981723,"user_tz":0,"elapsed":21,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def CNNDiscriminator(init_features=4,dropout_rate=0):\n","    h=40\n","    w=128\n","    d=128\n","    axial_model=CNN(h*w,init_features=init_features,dropout_rate=dropout_rate)\n","    sagittal_model=CNN(w*d,init_features=init_features,dropout_rate=dropout_rate)\n","    coronal_model=CNN(h*d,init_features=init_features,dropout_rate=dropout_rate)\n","    return SliceWiseModel(axial_model,sagittal_model,coronal_model)"]},{"cell_type":"markdown","metadata":{"id":"9QtOdGSY8Sek"},"source":["This is a transformer model"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"I_sV783JS5KC","executionInfo":{"status":"ok","timestamp":1679648981723,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class MyMSA(nn.Module):\n","    def __init__(self, d, n_heads=2):\n","        super(MyMSA, self).__init__()\n","        self.d = d\n","        self.n_heads = n_heads\n","\n","        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n","\n","        d_head = int(d / n_heads)\n","        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n","        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n","        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n","        self.d_head = d_head\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, sequences):\n","        # Sequences has shape (N, seq_length, token_dim)\n","        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n","        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n","        result = []\n","        for sequence in sequences:\n","            seq_result = []\n","            for head in range(self.n_heads):\n","                q_mapping = self.q_mappings[head]\n","                k_mapping = self.k_mappings[head]\n","                v_mapping = self.v_mappings[head]\n","\n","                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n","                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n","\n","                attention = self.softmax(torch.matmul(q,k.T)/np.sqrt(self.d))\n","                seq_result.append(torch.matmul(attention,v))\n","            result.append(torch.hstack(seq_result))\n","        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TwBI7PpqS6bg","executionInfo":{"status":"ok","timestamp":1679648981723,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class MyViTBlock(nn.Module):\n","    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n","        super(MyViTBlock, self).__init__()\n","        self.hidden_d = hidden_d\n","        self.n_heads = n_heads\n","\n","        self.norm1 = nn.LayerNorm(hidden_d)\n","        self.mhsa = MyMSA(hidden_d, n_heads)\n","        self.norm2 = nn.LayerNorm(hidden_d)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_d,mlp_ratio*hidden_d),\n","            nn.GELU(),\n","            nn.Linear(mlp_ratio*hidden_d,hidden_d)\n","        )\n","\n","    def forward(self, x):\n","        out = x+self.mhsa(self.norm1(x))\n","        temp = self.norm2(out)\n","        out = temp+self.mlp(temp)\n","        return out"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"6blvJkgPTah3","executionInfo":{"status":"ok","timestamp":1679648981723,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def patchify(images, patch_size):\n","    n, c, h, w = images.shape\n","\n","    n_patches1=h//patch_size\n","    n_patches2=w//patch_size\n","\n","    patches=images.unfold(2,patch_size,patch_size).unfold(3,patch_size,patch_size)\n","\n","    patches=patches.flatten(4)\n","\n","    patches=torch.cat((patches[:,0,:,:,:],patches[:,1,:,:,:]),3)\n","\n","    patches=torch.stack([patches[:,i,j,:] for i in range(n_patches1) for j in range(n_patches2)],1)\n","\n","    return patches"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"x1TYJq0uTezG","executionInfo":{"status":"ok","timestamp":1679648981723,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def get_positional_embeddings(sequence_length, d):\n","    result = torch.ones(sequence_length, d)\n","    for i in range(sequence_length):\n","        for j in range(d):\n","            if j%2==0:\n","                result[i][j]=np.sin(i/np.power(10000,j/d))\n","            else:\n","                result[i][j]=np.cos(i/np.power(10000,(j-1)/d))\n","    return result"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"T0NxLlLqS-ag","executionInfo":{"status":"ok","timestamp":1679648981724,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["class MyViT(nn.Module):\n","    def __init__(self, image_shape, patch_size=8, n_blocks=2, hidden_d=16, n_heads=2, out_d=1):\n","        # Super constructor\n","        super(MyViT, self).__init__()\n","        \n","        # Attributes\n","        self.image_shape = image_shape # ( C , H , W )\n","        self.n_blocks = n_blocks\n","        self.n_heads = n_heads\n","        self.hidden_d = hidden_d\n","        \n","        c,h,w=image_shape\n","        # Input and patches sizes\n","        assert h%patch_size==0\n","        assert w%patch_size==0\n","        n_patches1=h//patch_size\n","        n_patches2=w//patch_size\n","\n","        self.patch_size = patch_size\n","        \n","        # 1) Linear mapper\n","        self.input_d = int(image_shape[0] * patch_size**2)\n","        self.linear_mapper = nn.Linear(self.input_d,hidden_d)\n","        \n","        # 2) Learnable classification token\n","        self.class_token = nn.Parameter(torch.rand(hidden_d))\n","        \n","        # 3) Positional embedding - this creates a property called self.positional_embeddings\n","        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches1*n_patches2 + 1, hidden_d), persistent=False)\n","        \n","        # 4) Transformer encoder blocks\n","        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n","        \n","        # 5) Classification MLPk\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_d,out_d),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, images):\n","        # Dividing images into patches\n","        n, c, h, w = images.shape\n","        patches = patchify(images, self.patch_size)\n","        \n","        # Running linear layer tokenization\n","        # Map the vector corresponding to each patch to the hidden size dimension\n","        tokens = self.linear_mapper(patches)\n","        \n","        # Adding classification token to the tokens\n","        tokens = torch.cat((self.class_token.repeat(n,1,1),tokens),dim=1)   \n","        \n","        # Adding positional embedding\n","        out = tokens+self.positional_embeddings.repeat(n,1,1)\n","        \n","        # Transformer Blocks\n","        for block in self.blocks:\n","            out = block(out)\n","            \n","        # Getting the classification token only\n","        out = out[:,0,:]\n","        \n","        return self.mlp(out) # Map to output dimension, output category distribution"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"106oMWJGVSIH","executionInfo":{"status":"ok","timestamp":1679648981724,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def ViTDiscriminator(n_blocks=2,n_heads=2,hidden_d=8):\n","    c=2\n","    h=40\n","    w=128\n","    d=128\n","    axial_model=MyViT((c,h,w),n_blocks=n_blocks,n_heads=n_heads,hidden_d=hidden_d)\n","    sagittal_model=MyViT((c,w,d),n_blocks=n_blocks,n_heads=n_heads,hidden_d=hidden_d)\n","    coronal_model=MyViT((c,h,d),n_blocks=n_blocks,n_heads=n_heads,hidden_d=hidden_d)\n","    return SliceWiseModel(axial_model,sagittal_model,coronal_model)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"qpCJPnXl1Vcb","executionInfo":{"status":"ok","timestamp":1679648981724,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["discriminators={\n","    'ANN': ANNDiscriminator,\n","    'CNN': CNNDiscriminator,\n","    'ViT': ViTDiscriminator\n","}"]},{"cell_type":"markdown","metadata":{"id":"8FQqyojwWEX1"},"source":["# Training Code"]},{"cell_type":"markdown","metadata":{"id":"IpAQO2CpZerp"},"source":["Loss Functions"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"DwdQvR39Zimf","executionInfo":{"status":"ok","timestamp":1679648981724,"user_tz":0,"elapsed":20,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def dummy_discriminator(x):\n","    n=len(x)\n","    return torch.ones(n,1)\n","\n","class GANSegLoss(nn.Module):\n","    def __init__(self,discriminator=dummy_discriminator,lamda=1):\n","        super(GANSegLoss,self).__init__()\n","        self.discriminator=discriminator\n","        self.lamda=lamda\n","        self.loss=nn.BCELoss()\n","\n","    def forward(self,image,seg_pred,seg_target):\n","        first_term=self.loss(seg_pred,seg_target)\n","        dis_pred=self.discriminator(torch.cat((image,seg_pred),1))\n","        second_term=self.lamda*self.loss(dis_pred,torch.ones(dis_pred.shape).to(device))\n","        return first_term+second_term\n","\n","    def set_discriminator(self,discriminator):\n","        self.discriminator=discriminator\n","\n","class GANDisLoss(nn.Module):\n","    def __init__(self):\n","        super(GANDisLoss,self).__init__()\n","        self.loss=nn.BCELoss()\n","    \n","    def forward(self,true_pred,false_pred):\n","        true,false=true_pred.flatten(),false_pred.flatten()\n","        return self.loss(torch.cat((true,false),0),torch.cat((torch.ones(true.shape).to(device),torch.zeros(false.shape).to(device)),0))"]},{"cell_type":"markdown","metadata":{"id":"rdDFFb5Nl7-Z"},"source":["Training step for the segmentation network and discriminator network in GAN training and a function to evaluate the dice score of the segmentation network on the validation set"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"IzUH7ELIl_3r","executionInfo":{"status":"ok","timestamp":1679648982162,"user_tz":0,"elapsed":457,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score,f1_score\n","\n","def seg_train(seg_net,dis_net, dataloader, optim, loss_func, epoch):\n","    seg_net.train()  #Put the network in train mode\n","    dis_net.eval()\n","    total_loss = 0\n","    pred_store = []\n","    true_store = []\n","    \n","    batches = 0\n","    \n","    for batch_idx, (data, target) in enumerate(dataloader):\n","\n","        data, target = Variable(data), Variable(target)\n","        batches += 1\n","\n","        # Define training process here:\n","\n","        seg_net.zero_grad()\n","        optim.zero_grad() \n","\n","        pred=seg_net(data)\n","        loss=loss_func(data.float(),pred.float(),target.float())\n","        \n","        loss.backward()\n","        optim.step()  \n","        \n","        total_loss += loss\n","        pred_store.append(np.round(pred.detach().cpu().numpy()))\n","        true_store.append(np.round(target.detach().cpu().numpy()))\n","\n","        if batch_idx % 100 == 0: #Report stats every x batches\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, (batch_idx+1) * len(data), len(dataloader.dataset),\n","                           100. * (batch_idx+1) / len(dataloader), loss.item()), flush=True)\n","\n","    \n","    av_loss = total_loss / batches\n","    av_loss = av_loss.detach().cpu().numpy()\n","\n","    pred_store = np.concatenate(pred_store)\n","    true_store = np.concatenate(true_store)\n","    acc = accuracy_score(pred_store.flatten(), true_store.flatten())\n","\n","    print('\\nTraining set: Average loss: {:.4f}'.format(av_loss,  flush=True))\n","    print('Training set: Average Pixel Acc: {:.4f}'.format(acc,  flush=True))\n","    return av_loss, acc\n","\n","def dis_train(seg_net,dis_net, dataloader, optim, loss_func, epoch):\n","    seg_net.eval()  #Put the network in train mode\n","    dis_net.train()\n","    total_loss = 0\n","    pred_store = []\n","    true_store = []\n","\n","    batches = 0\n","    \n","    for batch_idx, (true,false) in enumerate(dataloader):\n","        true,false = Variable(true), Variable(false)\n","        batches += 1\n","\n","        dis_net.zero_grad()\n","        optim.zero_grad() \n","\n","        true_pred=dis_net(true)\n","        false_pred=dis_net(false)\n","        loss=loss_func(true_pred.float(),false_pred.float())\n","        \n","        loss.backward()\n","        optim.step()  \n","        \n","        total_loss += loss\n","        pred_store.append(np.round(true_pred.detach().cpu().numpy()))\n","        pred_store.append(np.round(false_pred.detach().cpu().numpy()))\n","        true_store.append(torch.ones(true_pred.shape).numpy())\n","        true_store.append(torch.zeros(false_pred.shape).numpy())\n","\n","        if batch_idx % 100 == 0: #Report stats every x batches\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, (batch_idx+1) * len(true), len(dataloader.dataset),\n","                           100. * (batch_idx+1) / len(dataloader), loss.item()), flush=True)\n","    \n","    av_loss = total_loss / batches\n","    av_loss = av_loss.detach().cpu().numpy()\n","\n","    pred_store = np.concatenate(pred_store)\n","    true_store = np.concatenate(true_store)\n","    acc = accuracy_score(pred_store, true_store)\n","\n","    print('\\nTraining set: Average loss: {:.4f}'.format(av_loss,  flush=True))\n","    print('Training set: Average Acc: {:.4f}'.format(acc,  flush=True))\n","    return av_loss, acc\n","\n","def predict(net, test_dataloader,class_labels=True):\n","    pred_store = []\n","    true_store = []\n","    net.eval()\n","    for batch_idx, (data, target) in enumerate(test_dataloader):\n","\n","        data, target = Variable(data), Variable(target)\n","        pred=net(data)\n","        if class_labels:\n","            pred_store.append(np.round(pred.detach().cpu().numpy()))\n","            true_store.append(np.round(target.detach().cpu().numpy()))\n","        else:\n","            pred_store.append(pred.detach().cpu().numpy())\n","            true_store.append(target.detach().cpu().numpy())\n","\n","\n","    pred_store = np.concatenate(pred_store)\n","    true_store = np.concatenate(true_store)\n","    return pred_store, true_store\n","\n","def seg_val(seg_net, val_dataloader):\n","    pred_store,true_store=predict(seg_net,val_dataloader)\n","    pred_store=pred_store.flatten()\n","    true_store=true_store.flatten()\n","    temp=f1_score(true_store,pred_store)\n","    print('Validation Set: Dice Score ',temp)\n","    return temp"]},{"cell_type":"markdown","metadata":{"id":"jCmLUBIP2hGL"},"source":["A function to train the networks in a GAN"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"bXGXECnP7eMt","executionInfo":{"status":"ok","timestamp":1679648982162,"user_tz":0,"elapsed":7,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def GANtrain(seg_net,dis_net,seg_dataloader,dis_dataloader,val_dataloader,max_epochs=50,lr1=0.01,lr2=0.01,n1=1,n2=1,lamda=1):\n","    dice = []\n","    seg_losses=[]\n","    dis_losses=[]\n","    seg_path='seg_model'\n","    dis_path='dis_model'\n","    best_dice=seg_val(seg_net,val_dataloader)\n","    torch.save(seg_net.state_dict(),seg_path)\n","    torch.save(dis_net.state_dict(),dis_path)\n","    seg_optim=torch.optim.Adam(seg_net.parameters(),lr=lr1)\n","    dis_optim=torch.optim.Adam(dis_net.parameters(),lr=lr2)\n","    seg_loss=GANSegLoss(dis_net,lamda).to(device)\n","    dis_loss=GANDisLoss().to(device)\n","    dis_dataloader.set_model(seg_net)\n","    for epoch in range(1, max_epochs+1):\n","        for _ in range(n1):\n","            train_loss, train_acc = seg_train(seg_net,dis_net, seg_dataloader, seg_optim, seg_loss, epoch)\n","            seg_losses.append([train_loss,train_acc])\n","        for _ in range(n2):\n","            train_loss, train_acc = dis_train(seg_net,dis_net, dis_dataloader, dis_optim, dis_loss, epoch)\n","            dis_losses.append([train_loss,train_acc])\n","        die = seg_val(seg_net, val_dataloader)\n","        dice.append(die)\n","        if die>best_dice:\n","            best_dice=die\n","            torch.save(seg_net.state_dict(),seg_path)\n","            torch.save(dis_net.state_dict(),dis_path)\n","    seg_net.load_state_dict(torch.load(seg_path))\n","    dis_net.load_state_dict(torch.load(dis_path))\n","    return dice,seg_losses,dis_losses"]},{"cell_type":"markdown","metadata":{"id":"QQOEenm7afnK"},"source":["A function to choose the best lambda value by training the model for 3 epochs and selecting the lambda value that gave the best dice score on the validation data"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ryV1fAUGcAyN","executionInfo":{"status":"ok","timestamp":1679648982162,"user_tz":0,"elapsed":7,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def get_lambda(seg_name,dis_name):\n","    try:\n","        with open('/content/drive/MyDrive/healthcare data/lambda'+seg_name+dis_name,'rb') as f:\n","            return pickle.load(f)\n","    except:\n","        torch.manual_seed(2718281828)\n","        values=[0.01,0.1,0.5]\n","        best_dice=0\n","        best_value=0\n","        for value in values:\n","            seg_net=SliceWiseModel.same_model(segmentation_models[seg_name]().to(device))\n","            dis_net=discriminators[dis_name]()\n","            n=2 if (dis_name=='ViT' or dis_name=='CNN') else 1\n","            dice,_,_=GANtrain(seg_net,dis_net,train_dataloader,train_discriminator_dataloader,val_dataloader,max_epochs=3,lamda=value,n1=n)\n","            dice=max(dice)\n","            del seg_net\n","            del dis_net\n","            if dice>best_dice:\n","                best_dice=dice\n","                best_value=value\n","        with open('/content/drive/MyDrive/healthcare data/lambda'+seg_name+dis_name,'wb') as f:\n","            pickle.dump(best_value,f)\n","        return best_value"]},{"cell_type":"markdown","metadata":{"id":"Jf7UuNIP2sDs"},"source":["training and validation steps for the control models"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"FnsEdWOYDWY3","executionInfo":{"status":"ok","timestamp":1679648982162,"user_tz":0,"elapsed":6,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def train(net, dataloader, optim, loss_func, epoch):\n","    net.train()  #Put the network in train mode\n","    total_loss = 0\n","    batches = 0\n","    \n","    for batch_idx, (data, target) in enumerate(dataloader):\n","        data, target = Variable(data), Variable(target)\n","        batches += 1\n","\n","        net.zero_grad()\n","        optim.zero_grad() \n","\n","        pred=net(data)\n","        loss=loss_func(pred.float(),target.float())\n","        \n","        loss.backward()\n","        optim.step()\n","\n","        total_loss += loss\n","        if batch_idx % 100 == 0: #Report stats every x batches\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, (batch_idx+1) * len(data), len(dataloader.dataset),\n","                           100. * (batch_idx+1) / len(dataloader), loss.item()), flush=True)\n","    av_loss = total_loss / batches\n","    av_loss = av_loss.detach().cpu().numpy()\n","    print('\\nTraining set: Average loss: {:.4f}'.format(av_loss,  flush=True))\n","\n","    return av_loss\n","\n","def val(net, val_dataloader, loss_func):\n","    net.eval()  #Put the model in eval mode\n","    total_loss = 0    \n","    batches = 0\n","    with torch.no_grad():  # So no gradients accumulate\n","        for batch_idx, (data, target) in enumerate(val_dataloader):\n","            batches += 1\n","            data, target = Variable(data), Variable(target)\n","            # Eval steps\n","            pred=net(data)\n","            loss=loss_func(pred.float(),target.float())\n","\n","            total_loss += loss\n","        av_loss = total_loss / batches\n","        \n","    av_loss = av_loss.detach().cpu().numpy()\n","    print('Validation set: Average loss: {:.4f}'.format(av_loss,  flush=True))\n","    print('\\n')\n","    return av_loss\n","\n","def val_acc(net,val_dataloader):\n","    pred_store,true_store=predict(net,val_dataloader)\n","    temp=accuracy_score(true_store.flatten(),pred_store.flatten())\n","    print('Validation Set: Accuracy ',temp)\n","    return temp"]},{"cell_type":"markdown","metadata":{"id":"CDKpqTBj2wHq"},"source":["A function to train a segmentation network"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"HaH2UT8Iz896","executionInfo":{"status":"ok","timestamp":1679648982163,"user_tz":0,"elapsed":7,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def controlTrain(net,train_dataloader,val_dataloader,class_loss=nn.BCELoss().to(device),lr=0.01):\n","    losses = []\n","    max_epochs = 25\n","    optim=torch.optim.Adam(net.parameters(),lr=lr)\n","    path='model'\n","    best_dice=seg_val(net,val_dataloader)\n","    torch.save(net.state_dict(),path)\n","    dice=[]\n","    for epoch in range(1, max_epochs+1):\n","        train_loss = train(net, train_dataloader, optim, class_loss, epoch)\n","        val_loss = val(net, val_dataloader,class_loss)\n","        losses.append([train_loss, val_loss])\n","        die = seg_val(net, val_dataloader)\n","        dice.append(die)\n","        if die>best_dice:\n","            best_dice=die\n","            torch.save(net.state_dict(),path)\n","    net.load_state_dict(torch.load(path))\n","    return dice,losses"]},{"cell_type":"markdown","metadata":{"id":"2obphVTyXlZC"},"source":["A function to evaluate a segmentation model on the test data"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"GU9J7RYrXqvH","executionInfo":{"status":"ok","timestamp":1679648982163,"user_tz":0,"elapsed":7,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, jaccard_score, f1_score,precision_score,recall_score,roc_auc_score,confusion_matrix\n","\n","def evaluate(net,dataloader):\n","    torch.manual_seed(271828182)\n","    pred_store,true_store=predict(net,dataloader)\n","    pred_store=pred_store.flatten()\n","    true_store=true_store.flatten()\n","    print('Accuracy: ',accuracy_score(true_store,pred_store))\n","    print(\"Jaccard's Index: \",jaccard_score(true_store,pred_store))\n","    print('Dice Score: ',f1_score(true_store,pred_store))\n","    print('Precision: ',precision_score(true_store,pred_store))\n","    print('Recall: ',recall_score(true_store,pred_store))\n","    tn, fp, fn, tp = confusion_matrix(true_store,pred_store).ravel()\n","    print('Specificity: ',tn/(tn+fp))\n","    pred_store,true_store=predict(net,dataloader,False)\n","    pred_store=pred_store.flatten()\n","    true_store=true_store.flatten()\n","    print('AUC-ROC Score: ',roc_auc_score(true_store,pred_store))"]},{"cell_type":"markdown","metadata":{"id":"zXkpp5CH22uK"},"source":["# Training the control networks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUUmYPFNrZrZ"},"outputs":[],"source":["def get_control_model(seg_name):\n","    try:\n","        with open('/content/drive/MyDrive/healthcare data/'+seg_name,'rb') as f:\n","            return pickle.load(f)\n","    except Exception:\n","        torch.manual_seed(2718281828)  #manually seed the pytorch pseudo-random generators (with a seed based on e) to ensure repeatability\n","        model=SliceWiseModel.same_model(segmentation_models[seg_name]().to(device))\n","        model_stats=controlTrain(model,train_dataloader,val_dataloader)\n","        with open('/content/drive/MyDrive/healthcare data/'+seg_name,'wb') as f:\n","            pickle.dump((model,model_stats),f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBBEgEhk2_a6"},"outputs":[],"source":["for model_name in segmentation_models:\n","    _=get_control_model(model_name)"]},{"cell_type":"markdown","metadata":{"id":"hswKirdg3QBU"},"source":["#Evaluating Control Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jDpzwKkF3Vtb","outputId":"44f59725-fc21-4eac-ea20-51ffd9a93511"},"outputs":[{"name":"stdout","output_type":"stream","text":["Control Model:  CDNN\n","Accuracy:  0.938238525390625\n","Jaccard's Index:  0.8371325381403859\n","Dice Score:  0.911346917830722\n","Precision:  0.8782722773580912\n","Recall:  0.9470101406529788\n","Specificity:  0.9338154838225938\n","AUC-ROC Score:  0.9748269320586742\n","\n","Control Model:  UNet\n","Accuracy:  0.9467086065383185\n","Jaccard's Index:  0.8545759176422068\n","Dice Score:  0.9215863416674382\n","Precision:  0.9092912209014442\n","Recall:  0.9342185207431117\n","Specificity:  0.9530066676146601\n","AUC-ROC Score:  0.9782274071342195\n","\n","Control Model:  VNet\n","Accuracy:  0.9674538748604911\n","Jaccard's Index:  0.9062341427143151\n","Dice Score:  0.9508109443721482\n","Precision:  0.9635908872268616\n","Recall:  0.9383655607532041\n","Specificity:  0.9821215066013244\n","AUC-ROC Score:  0.9866804274400738\n","\n"]}],"source":["for seg_name in segmentation_models:\n","    print('Control Model: ',seg_name)\n","    model,_=get_control_model(seg_name)\n","    evaluate(model,test_dataloader)\n","    print()\n","    del model"]},{"cell_type":"markdown","metadata":{"id":"rRUW2w5Fpw7h"},"source":["#Training GAN Models"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"UKm3bg4Pp1IR","executionInfo":{"status":"ok","timestamp":1679648982163,"user_tz":0,"elapsed":7,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[],"source":["def get_GAN_model(seg_name,dis_name):\n","    try:\n","        with open('/content/drive/MyDrive/healthcare data/'+seg_name+dis_name,'rb') as f:\n","            return pickle.load(f)\n","    except Exception:\n","        torch.manual_seed(2718281828)  #manually seed the pytorch pseudo-random generators (with a seed based on e) to ensure repeatability\n","        lamda=get_lambda(seg_name,dis_name)\n","        seg_net=SliceWiseModel.same_model(segmentation_models[seg_name]()).to(device)\n","        dis_net=discriminators[dis_name]().to(device)\n","        n=2 if (dis_name=='ViT' or dis_name=='CNN') else 1\n","        results=GANtrain(seg_net,dis_net,train_dataloader,train_discriminator_dataloader,val_dataloader,lamda=lamda,n1=n)\n","        with open('/content/drive/MyDrive/healthcare data/'+seg_name+dis_name,'wb') as f:\n","            pickle.dump(((seg_net,dis_net),results),f)\n","        return (seg_net,dis_net),results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0T1C8eXMhWB"},"outputs":[],"source":["for seg_name in segmentation_models:\n","    for dis_name in discriminators:\n","        _=get_GAN_model(seg_name,dis_name)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWhh3TA9MiDf","outputId":"312f600c-b4ea-4422-d5af-f298e2b0ad04","executionInfo":{"status":"ok","timestamp":1679664006213,"user_tz":0,"elapsed":15024056,"user":{"displayName":"Ab F","userId":"10662768669440018821"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Set: Dice Score  0.5366234891401189\n","Train Epoch: 1 [8/63 (14%)]\tLoss: 1.136685\n","\n","Training set: Average loss: 0.9431\n","Training set: Average Pixel Acc: 0.8023\n","Train Epoch: 1 [8/63 (14%)]\tLoss: 0.822126\n","\n","Training set: Average loss: 0.7968\n","Training set: Average Pixel Acc: 0.8947\n","Train Epoch: 1 [8/63 (14%)]\tLoss: 0.705695\n","\n","Training set: Average loss: 0.5691\n","Training set: Average Acc: 0.8036\n","Validation Set: Dice Score  0.8134520717396918\n","Train Epoch: 2 [8/63 (14%)]\tLoss: 0.889989\n","\n","Training set: Average loss: 0.7514\n","Training set: Average Pixel Acc: 0.8646\n","Train Epoch: 2 [8/63 (14%)]\tLoss: 0.587168\n","\n","Training set: Average loss: 0.5228\n","Training set: Average Pixel Acc: 0.8821\n","Train Epoch: 2 [8/63 (14%)]\tLoss: 0.778876\n","\n","Training set: Average loss: 0.4818\n","Training set: Average Acc: 0.7946\n","Validation Set: Dice Score  0.8101106662293046\n","Train Epoch: 3 [8/63 (14%)]\tLoss: 0.949185\n","\n","Training set: Average loss: 0.7557\n","Training set: Average Pixel Acc: 0.9057\n","Train Epoch: 3 [8/63 (14%)]\tLoss: 0.534282\n","\n","Training set: Average loss: 0.4335\n","Training set: Average Pixel Acc: 0.9138\n","Train Epoch: 3 [8/63 (14%)]\tLoss: 0.929970\n","\n","Training set: Average loss: 0.6738\n","Training set: Average Acc: 0.6161\n","Validation Set: Dice Score  0.7648848823541561\n","Train Epoch: 4 [8/63 (14%)]\tLoss: 1.512011\n","\n","Training set: Average loss: 1.3578\n","Training set: Average Pixel Acc: 0.8662\n","Train Epoch: 4 [8/63 (14%)]\tLoss: 1.179030\n","\n","Training set: Average loss: 1.1125\n","Training set: Average Pixel Acc: 0.8631\n","Train Epoch: 4 [8/63 (14%)]\tLoss: 0.700720\n","\n","Training set: Average loss: 0.5791\n","Training set: Average Acc: 0.7054\n","Validation Set: Dice Score  0.7855380173440177\n","Train Epoch: 5 [8/63 (14%)]\tLoss: 0.721850\n","\n","Training set: Average loss: 0.7349\n","Training set: Average Pixel Acc: 0.8730\n","Train Epoch: 5 [8/63 (14%)]\tLoss: 0.671535\n","\n","Training set: Average loss: 0.6695\n","Training set: Average Pixel Acc: 0.8910\n","Train Epoch: 5 [8/63 (14%)]\tLoss: 0.638556\n","\n","Training set: Average loss: 0.4401\n","Training set: Average Acc: 0.8571\n","Validation Set: Dice Score  0.8064682658389435\n","Train Epoch: 6 [8/63 (14%)]\tLoss: 0.601709\n","\n","Training set: Average loss: 0.6488\n","Training set: Average Pixel Acc: 0.8809\n","Train Epoch: 6 [8/63 (14%)]\tLoss: 0.552859\n","\n","Training set: Average loss: 0.6203\n","Training set: Average Pixel Acc: 0.8871\n","Train Epoch: 6 [8/63 (14%)]\tLoss: 0.542893\n","\n","Training set: Average loss: 0.5411\n","Training set: Average Acc: 0.7411\n","Validation Set: Dice Score  0.7884640770654968\n","Train Epoch: 7 [8/63 (14%)]\tLoss: 0.768453\n","\n","Training set: Average loss: 0.7461\n","Training set: Average Pixel Acc: 0.8977\n","Train Epoch: 7 [8/63 (14%)]\tLoss: 0.692625\n","\n","Training set: Average loss: 0.7199\n","Training set: Average Pixel Acc: 0.8994\n","Train Epoch: 7 [8/63 (14%)]\tLoss: 0.529435\n","\n","Training set: Average loss: 0.5233\n","Training set: Average Acc: 0.8214\n","Validation Set: Dice Score  0.8161163940119733\n","Train Epoch: 8 [8/63 (14%)]\tLoss: 0.687970\n","\n","Training set: Average loss: 0.7883\n","Training set: Average Pixel Acc: 0.9012\n","Train Epoch: 8 [8/63 (14%)]\tLoss: 0.892035\n","\n","Training set: Average loss: 0.7502\n","Training set: Average Pixel Acc: 0.9124\n","Train Epoch: 8 [8/63 (14%)]\tLoss: 0.587548\n","\n","Training set: Average loss: 0.5147\n","Training set: Average Acc: 0.7857\n","Validation Set: Dice Score  0.8360944848460127\n","Train Epoch: 9 [8/63 (14%)]\tLoss: 0.893190\n","\n","Training set: Average loss: 0.9482\n","Training set: Average Pixel Acc: 0.8915\n","Train Epoch: 9 [8/63 (14%)]\tLoss: 0.934336\n","\n","Training set: Average loss: 0.9363\n","Training set: Average Pixel Acc: 0.8819\n","Train Epoch: 9 [8/63 (14%)]\tLoss: 0.404196\n","\n","Training set: Average loss: 0.4061\n","Training set: Average Acc: 0.8929\n","Validation Set: Dice Score  0.7553689645468903\n","Train Epoch: 10 [8/63 (14%)]\tLoss: 1.029696\n","\n","Training set: Average loss: 0.8350\n","Training set: Average Pixel Acc: 0.8711\n","Train Epoch: 10 [8/63 (14%)]\tLoss: 1.125084\n","\n","Training set: Average loss: 0.8100\n","Training set: Average Pixel Acc: 0.8855\n","Train Epoch: 10 [8/63 (14%)]\tLoss: 0.496471\n","\n","Training set: Average loss: 0.4980\n","Training set: Average Acc: 0.8393\n","Validation Set: Dice Score  0.75862202093365\n","Train Epoch: 11 [8/63 (14%)]\tLoss: 0.988291\n","\n","Training set: Average loss: 0.8390\n","Training set: Average Pixel Acc: 0.8904\n","Train Epoch: 11 [8/63 (14%)]\tLoss: 0.860758\n","\n","Training set: Average loss: 0.8268\n","Training set: Average Pixel Acc: 0.9022\n","Train Epoch: 11 [8/63 (14%)]\tLoss: 0.552540\n","\n","Training set: Average loss: 0.4759\n","Training set: Average Acc: 0.7946\n","Validation Set: Dice Score  0.8123628386625793\n","Train Epoch: 12 [8/63 (14%)]\tLoss: 0.774162\n","\n","Training set: Average loss: 0.8143\n","Training set: Average Pixel Acc: 0.8930\n","Train Epoch: 12 [8/63 (14%)]\tLoss: 0.702892\n","\n","Training set: Average loss: 0.7828\n","Training set: Average Pixel Acc: 0.8801\n","Train Epoch: 12 [8/63 (14%)]\tLoss: 0.501817\n","\n","Training set: Average loss: 0.4939\n","Training set: Average Acc: 0.8125\n","Validation Set: Dice Score  0.6888578337956657\n","Train Epoch: 13 [8/63 (14%)]\tLoss: 0.809768\n","\n","Training set: Average loss: 0.8106\n","Training set: Average Pixel Acc: 0.8791\n","Train Epoch: 13 [8/63 (14%)]\tLoss: 0.822892\n","\n","Training set: Average loss: 0.7456\n","Training set: Average Pixel Acc: 0.9082\n","Train Epoch: 13 [8/63 (14%)]\tLoss: 0.395084\n","\n","Training set: Average loss: 0.4109\n","Training set: Average Acc: 0.8661\n","Validation Set: Dice Score  0.8224181797847369\n","Train Epoch: 14 [8/63 (14%)]\tLoss: 0.727935\n","\n","Training set: Average loss: 0.7202\n","Training set: Average Pixel Acc: 0.8899\n","Train Epoch: 14 [8/63 (14%)]\tLoss: 0.560699\n","\n","Training set: Average loss: 0.7686\n","Training set: Average Pixel Acc: 0.8775\n","Train Epoch: 14 [8/63 (14%)]\tLoss: 0.631729\n","\n","Training set: Average loss: 0.6149\n","Training set: Average Acc: 0.6339\n","Validation Set: Dice Score  0.6728264944575068\n","Train Epoch: 15 [8/63 (14%)]\tLoss: 0.552692\n","\n","Training set: Average loss: 0.6014\n","Training set: Average Pixel Acc: 0.8855\n","Train Epoch: 15 [8/63 (14%)]\tLoss: 0.522764\n","\n","Training set: Average loss: 0.5332\n","Training set: Average Pixel Acc: 0.9117\n","Train Epoch: 15 [8/63 (14%)]\tLoss: 0.525749\n","\n","Training set: Average loss: 0.5222\n","Training set: Average Acc: 0.7857\n","Validation Set: Dice Score  0.8370705416144566\n","Train Epoch: 16 [8/63 (14%)]\tLoss: 0.691801\n","\n","Training set: Average loss: 0.7869\n","Training set: Average Pixel Acc: 0.8931\n","Train Epoch: 16 [8/63 (14%)]\tLoss: 0.973140\n","\n","Training set: Average loss: 0.7100\n","Training set: Average Pixel Acc: 0.8787\n","Train Epoch: 16 [8/63 (14%)]\tLoss: 0.529345\n","\n","Training set: Average loss: 0.4324\n","Training set: Average Acc: 0.9107\n","Validation Set: Dice Score  0.8179056858152128\n","Train Epoch: 17 [8/63 (14%)]\tLoss: 1.007572\n","\n","Training set: Average loss: 0.8517\n","Training set: Average Pixel Acc: 0.8663\n","Train Epoch: 17 [8/63 (14%)]\tLoss: 0.723966\n","\n","Training set: Average loss: 0.7962\n","Training set: Average Pixel Acc: 0.8785\n","Train Epoch: 17 [8/63 (14%)]\tLoss: 0.460500\n","\n","Training set: Average loss: 0.4617\n","Training set: Average Acc: 0.8304\n","Validation Set: Dice Score  0.8077674782730543\n","Train Epoch: 18 [8/63 (14%)]\tLoss: 0.487743\n","\n","Training set: Average loss: 0.6304\n","Training set: Average Pixel Acc: 0.8813\n","Train Epoch: 18 [8/63 (14%)]\tLoss: 0.577118\n","\n","Training set: Average loss: 0.6031\n","Training set: Average Pixel Acc: 0.9014\n","Train Epoch: 18 [8/63 (14%)]\tLoss: 0.432447\n","\n","Training set: Average loss: 0.4410\n","Training set: Average Acc: 0.8304\n","Validation Set: Dice Score  0.8058998308924956\n","Train Epoch: 19 [8/63 (14%)]\tLoss: 0.959833\n","\n","Training set: Average loss: 0.7215\n","Training set: Average Pixel Acc: 0.9092\n","Train Epoch: 19 [8/63 (14%)]\tLoss: 0.748062\n","\n","Training set: Average loss: 0.7431\n","Training set: Average Pixel Acc: 0.8848\n","Train Epoch: 19 [8/63 (14%)]\tLoss: 0.466851\n","\n","Training set: Average loss: 0.5141\n","Training set: Average Acc: 0.7857\n","Validation Set: Dice Score  0.7366320262454527\n","Train Epoch: 20 [8/63 (14%)]\tLoss: 0.931735\n","\n","Training set: Average loss: 0.7809\n","Training set: Average Pixel Acc: 0.8892\n","Train Epoch: 20 [8/63 (14%)]\tLoss: 0.668425\n","\n","Training set: Average loss: 0.7924\n","Training set: Average Pixel Acc: 0.8727\n","Train Epoch: 20 [8/63 (14%)]\tLoss: 0.504399\n","\n","Training set: Average loss: 0.4626\n","Training set: Average Acc: 0.8214\n","Validation Set: Dice Score  0.7764478845099244\n","Train Epoch: 21 [8/63 (14%)]\tLoss: 0.596196\n","\n","Training set: Average loss: 0.6377\n","Training set: Average Pixel Acc: 0.8840\n","Train Epoch: 21 [8/63 (14%)]\tLoss: 0.462511\n","\n","Training set: Average loss: 0.6259\n","Training set: Average Pixel Acc: 0.8937\n","Train Epoch: 21 [8/63 (14%)]\tLoss: 0.575511\n","\n","Training set: Average loss: 0.5173\n","Training set: Average Acc: 0.8125\n","Validation Set: Dice Score  0.7950720462520983\n","Train Epoch: 22 [8/63 (14%)]\tLoss: 0.936221\n","\n","Training set: Average loss: 1.0037\n","Training set: Average Pixel Acc: 0.8871\n","Train Epoch: 22 [8/63 (14%)]\tLoss: 0.975069\n","\n","Training set: Average loss: 1.0386\n","Training set: Average Pixel Acc: 0.8824\n","Train Epoch: 22 [8/63 (14%)]\tLoss: 0.418326\n","\n","Training set: Average loss: 0.4447\n","Training set: Average Acc: 0.8482\n","Validation Set: Dice Score  0.7309227406788574\n","Train Epoch: 23 [8/63 (14%)]\tLoss: 0.873430\n","\n","Training set: Average loss: 0.6996\n","Training set: Average Pixel Acc: 0.8833\n","Train Epoch: 23 [8/63 (14%)]\tLoss: 0.678586\n","\n","Training set: Average loss: 0.7504\n","Training set: Average Pixel Acc: 0.8917\n","Train Epoch: 23 [8/63 (14%)]\tLoss: 0.574730\n","\n","Training set: Average loss: 0.5014\n","Training set: Average Acc: 0.7857\n","Validation Set: Dice Score  0.7614951384015923\n","Train Epoch: 24 [8/63 (14%)]\tLoss: 0.766253\n","\n","Training set: Average loss: 0.8682\n","Training set: Average Pixel Acc: 0.8908\n","Train Epoch: 24 [8/63 (14%)]\tLoss: 0.945480\n","\n","Training set: Average loss: 0.8737\n","Training set: Average Pixel Acc: 0.9156\n","Train Epoch: 24 [8/63 (14%)]\tLoss: 0.485123\n","\n","Training set: Average loss: 0.4764\n","Training set: Average Acc: 0.8393\n","Validation Set: Dice Score  0.7826966051333349\n","Train Epoch: 25 [8/63 (14%)]\tLoss: 0.825927\n","\n","Training set: Average loss: 0.8040\n","Training set: Average Pixel Acc: 0.9007\n","Train Epoch: 25 [8/63 (14%)]\tLoss: 0.818825\n","\n","Training set: Average loss: 0.8682\n","Training set: Average Pixel Acc: 0.8957\n","Train Epoch: 25 [8/63 (14%)]\tLoss: 0.412555\n","\n","Training set: Average loss: 0.4656\n","Training set: Average Acc: 0.8393\n","Validation Set: Dice Score  0.7567646646720899\n","Train Epoch: 26 [8/63 (14%)]\tLoss: 1.259976\n","\n","Training set: Average loss: 0.9557\n","Training set: Average Pixel Acc: 0.8891\n","Train Epoch: 26 [8/63 (14%)]\tLoss: 0.839071\n","\n","Training set: Average loss: 1.0085\n","Training set: Average Pixel Acc: 0.8798\n","Train Epoch: 26 [8/63 (14%)]\tLoss: 0.405936\n","\n","Training set: Average loss: 0.4267\n","Training set: Average Acc: 0.9018\n","Validation Set: Dice Score  0.7685262417714133\n","Train Epoch: 27 [8/63 (14%)]\tLoss: 0.558280\n","\n","Training set: Average loss: 0.6670\n","Training set: Average Pixel Acc: 0.8980\n","Train Epoch: 27 [8/63 (14%)]\tLoss: 0.625495\n","\n","Training set: Average loss: 0.6213\n","Training set: Average Pixel Acc: 0.9071\n","Train Epoch: 27 [8/63 (14%)]\tLoss: 0.478157\n","\n","Training set: Average loss: 0.4630\n","Training set: Average Acc: 0.9018\n","Validation Set: Dice Score  0.8132389984175561\n","Train Epoch: 28 [8/63 (14%)]\tLoss: 0.581976\n","\n","Training set: Average loss: 0.6599\n","Training set: Average Pixel Acc: 0.8926\n","Train Epoch: 28 [8/63 (14%)]\tLoss: 0.600303\n","\n","Training set: Average loss: 0.6510\n","Training set: Average Pixel Acc: 0.9099\n","Train Epoch: 28 [8/63 (14%)]\tLoss: 0.436554\n","\n","Training set: Average loss: 0.4179\n","Training set: Average Acc: 0.9375\n","Validation Set: Dice Score  0.850521509523899\n","Train Epoch: 29 [8/63 (14%)]\tLoss: 0.509179\n","\n","Training set: Average loss: 0.5475\n","Training set: Average Pixel Acc: 0.9098\n","Train Epoch: 29 [8/63 (14%)]\tLoss: 0.445428\n","\n","Training set: Average loss: 0.5299\n","Training set: Average Pixel Acc: 0.9072\n","Train Epoch: 29 [8/63 (14%)]\tLoss: 0.605733\n","\n","Training set: Average loss: 0.5276\n","Training set: Average Acc: 0.7679\n","Validation Set: Dice Score  0.8242212244261896\n","Train Epoch: 30 [8/63 (14%)]\tLoss: 0.675037\n","\n","Training set: Average loss: 0.6832\n","Training set: Average Pixel Acc: 0.9117\n","Train Epoch: 30 [8/63 (14%)]\tLoss: 0.564022\n","\n","Training set: Average loss: 0.6413\n","Training set: Average Pixel Acc: 0.9073\n","Train Epoch: 30 [8/63 (14%)]\tLoss: 0.428264\n","\n","Training set: Average loss: 0.4985\n","Training set: Average Acc: 0.7768\n","Validation Set: Dice Score  0.7942130975617488\n","Train Epoch: 31 [8/63 (14%)]\tLoss: 0.580056\n","\n","Training set: Average loss: 0.6755\n","Training set: Average Pixel Acc: 0.9159\n","Train Epoch: 31 [8/63 (14%)]\tLoss: 0.611330\n","\n","Training set: Average loss: 0.6366\n","Training set: Average Pixel Acc: 0.9237\n","Train Epoch: 31 [8/63 (14%)]\tLoss: 0.557009\n","\n","Training set: Average loss: 0.4840\n","Training set: Average Acc: 0.8571\n","Validation Set: Dice Score  0.7575896225734979\n","Train Epoch: 32 [8/63 (14%)]\tLoss: 0.563509\n","\n","Training set: Average loss: 0.7109\n","Training set: Average Pixel Acc: 0.9033\n","Train Epoch: 32 [8/63 (14%)]\tLoss: 0.575812\n","\n","Training set: Average loss: 0.6933\n","Training set: Average Pixel Acc: 0.8814\n","Train Epoch: 32 [8/63 (14%)]\tLoss: 0.528072\n","\n","Training set: Average loss: 0.4518\n","Training set: Average Acc: 0.8214\n","Validation Set: Dice Score  0.5538267272959718\n","Train Epoch: 33 [8/63 (14%)]\tLoss: 0.837370\n","\n","Training set: Average loss: 0.9180\n","Training set: Average Pixel Acc: 0.8895\n","Train Epoch: 33 [8/63 (14%)]\tLoss: 0.975874\n","\n","Training set: Average loss: 0.9488\n","Training set: Average Pixel Acc: 0.9253\n","Train Epoch: 33 [8/63 (14%)]\tLoss: 0.389526\n","\n","Training set: Average loss: 0.3564\n","Training set: Average Acc: 0.8839\n","Validation Set: Dice Score  0.8629811269136053\n","Train Epoch: 34 [8/63 (14%)]\tLoss: 0.753961\n","\n","Training set: Average loss: 0.7082\n","Training set: Average Pixel Acc: 0.9127\n","Train Epoch: 34 [8/63 (14%)]\tLoss: 0.612392\n","\n","Training set: Average loss: 0.6652\n","Training set: Average Pixel Acc: 0.8731\n","Train Epoch: 34 [8/63 (14%)]\tLoss: 0.554747\n","\n","Training set: Average loss: 0.4209\n","Training set: Average Acc: 0.8571\n","Validation Set: Dice Score  0.7287183723911991\n","Train Epoch: 35 [8/63 (14%)]\tLoss: 0.717510\n","\n","Training set: Average loss: 0.8585\n","Training set: Average Pixel Acc: 0.8902\n","Train Epoch: 35 [8/63 (14%)]\tLoss: 0.831236\n","\n","Training set: Average loss: 0.8778\n","Training set: Average Pixel Acc: 0.8989\n","Train Epoch: 35 [8/63 (14%)]\tLoss: 0.404720\n","\n","Training set: Average loss: 0.3667\n","Training set: Average Acc: 0.9107\n","Validation Set: Dice Score  0.8114464541661837\n","Train Epoch: 36 [8/63 (14%)]\tLoss: 0.612190\n","\n","Training set: Average loss: 0.7631\n","Training set: Average Pixel Acc: 0.9022\n","Train Epoch: 36 [8/63 (14%)]\tLoss: 0.749651\n","\n","Training set: Average loss: 0.8081\n","Training set: Average Pixel Acc: 0.8827\n","Train Epoch: 36 [8/63 (14%)]\tLoss: 0.341903\n","\n","Training set: Average loss: 0.3253\n","Training set: Average Acc: 0.9464\n","Validation Set: Dice Score  0.7041511100279703\n","Train Epoch: 37 [8/63 (14%)]\tLoss: 0.965715\n","\n","Training set: Average loss: 1.1186\n","Training set: Average Pixel Acc: 0.8742\n","Train Epoch: 37 [8/63 (14%)]\tLoss: 0.929569\n","\n","Training set: Average loss: 1.0454\n","Training set: Average Pixel Acc: 0.8710\n","Train Epoch: 37 [8/63 (14%)]\tLoss: 0.375558\n","\n","Training set: Average loss: 0.3695\n","Training set: Average Acc: 0.9286\n","Validation Set: Dice Score  0.7500308395938513\n","Train Epoch: 38 [8/63 (14%)]\tLoss: 1.025030\n","\n","Training set: Average loss: 1.0603\n","Training set: Average Pixel Acc: 0.8858\n","Train Epoch: 38 [8/63 (14%)]\tLoss: 1.316107\n","\n","Training set: Average loss: 1.0813\n","Training set: Average Pixel Acc: 0.8920\n","Train Epoch: 38 [8/63 (14%)]\tLoss: 0.241077\n","\n","Training set: Average loss: 0.3019\n","Training set: Average Acc: 0.9464\n","Validation Set: Dice Score  0.7876760458832729\n","Train Epoch: 39 [8/63 (14%)]\tLoss: 0.762837\n","\n","Training set: Average loss: 0.8399\n","Training set: Average Pixel Acc: 0.8927\n","Train Epoch: 39 [8/63 (14%)]\tLoss: 0.958852\n","\n","Training set: Average loss: 0.8446\n","Training set: Average Pixel Acc: 0.8816\n","Train Epoch: 39 [8/63 (14%)]\tLoss: 0.279422\n","\n","Training set: Average loss: 0.3107\n","Training set: Average Acc: 0.9464\n","Validation Set: Dice Score  0.720445132874462\n","Train Epoch: 40 [8/63 (14%)]\tLoss: 0.889335\n","\n","Training set: Average loss: 0.9847\n","Training set: Average Pixel Acc: 0.8775\n","Train Epoch: 40 [8/63 (14%)]\tLoss: 0.952980\n","\n","Training set: Average loss: 0.9538\n","Training set: Average Pixel Acc: 0.8953\n","Train Epoch: 40 [8/63 (14%)]\tLoss: 0.316893\n","\n","Training set: Average loss: 0.3196\n","Training set: Average Acc: 0.9643\n","Validation Set: Dice Score  0.7754758808610175\n","Train Epoch: 41 [8/63 (14%)]\tLoss: 1.038564\n","\n","Training set: Average loss: 0.9868\n","Training set: Average Pixel Acc: 0.8994\n","Train Epoch: 41 [8/63 (14%)]\tLoss: 0.812195\n","\n","Training set: Average loss: 0.9160\n","Training set: Average Pixel Acc: 0.8991\n","Train Epoch: 41 [8/63 (14%)]\tLoss: 0.384147\n","\n","Training set: Average loss: 0.3532\n","Training set: Average Acc: 0.9643\n","Validation Set: Dice Score  0.7194206378553119\n","Train Epoch: 42 [8/63 (14%)]\tLoss: 0.723264\n","\n","Training set: Average loss: 0.7608\n","Training set: Average Pixel Acc: 0.9037\n","Train Epoch: 42 [8/63 (14%)]\tLoss: 0.678670\n","\n","Training set: Average loss: 0.7826\n","Training set: Average Pixel Acc: 0.9127\n","Train Epoch: 42 [8/63 (14%)]\tLoss: 0.285154\n","\n","Training set: Average loss: 0.2462\n","Training set: Average Acc: 1.0000\n","Validation Set: Dice Score  0.8648806782021033\n","Train Epoch: 43 [8/63 (14%)]\tLoss: 0.948028\n","\n","Training set: Average loss: 0.8822\n","Training set: Average Pixel Acc: 0.9212\n","Train Epoch: 43 [8/63 (14%)]\tLoss: 0.779450\n","\n","Training set: Average loss: 0.8472\n","Training set: Average Pixel Acc: 0.8940\n","Train Epoch: 43 [8/63 (14%)]\tLoss: 0.515993\n","\n","Training set: Average loss: 0.3917\n","Training set: Average Acc: 0.8929\n","Validation Set: Dice Score  0.765170396536272\n","Train Epoch: 44 [8/63 (14%)]\tLoss: 1.118639\n","\n","Training set: Average loss: 1.1023\n","Training set: Average Pixel Acc: 0.9147\n","Train Epoch: 44 [8/63 (14%)]\tLoss: 1.293563\n","\n","Training set: Average loss: 1.1313\n","Training set: Average Pixel Acc: 0.9269\n","Train Epoch: 44 [8/63 (14%)]\tLoss: 0.327879\n","\n","Training set: Average loss: 0.3327\n","Training set: Average Acc: 0.9911\n","Validation Set: Dice Score  0.8405860454560106\n","Train Epoch: 45 [8/63 (14%)]\tLoss: 0.873094\n","\n","Training set: Average loss: 0.9554\n","Training set: Average Pixel Acc: 0.9293\n","Train Epoch: 45 [8/63 (14%)]\tLoss: 1.100978\n","\n","Training set: Average loss: 0.9358\n","Training set: Average Pixel Acc: 0.9303\n","Train Epoch: 45 [8/63 (14%)]\tLoss: 0.350075\n","\n","Training set: Average loss: 0.3477\n","Training set: Average Acc: 0.9732\n","Validation Set: Dice Score  0.8664348476602902\n","Train Epoch: 46 [8/63 (14%)]\tLoss: 0.900361\n","\n","Training set: Average loss: 0.9334\n","Training set: Average Pixel Acc: 0.9234\n","Train Epoch: 46 [8/63 (14%)]\tLoss: 1.022822\n","\n","Training set: Average loss: 0.9326\n","Training set: Average Pixel Acc: 0.9274\n","Train Epoch: 46 [8/63 (14%)]\tLoss: 0.300644\n","\n","Training set: Average loss: 0.3004\n","Training set: Average Acc: 0.9821\n","Validation Set: Dice Score  0.8737118133794527\n","Train Epoch: 47 [8/63 (14%)]\tLoss: 0.948496\n","\n","Training set: Average loss: 1.0772\n","Training set: Average Pixel Acc: 0.9285\n","Train Epoch: 47 [8/63 (14%)]\tLoss: 0.923397\n","\n","Training set: Average loss: 1.0570\n","Training set: Average Pixel Acc: 0.9347\n","Train Epoch: 47 [8/63 (14%)]\tLoss: 0.278956\n","\n","Training set: Average loss: 0.3086\n","Training set: Average Acc: 0.9911\n","Validation Set: Dice Score  0.8891673489309971\n","Train Epoch: 48 [8/63 (14%)]\tLoss: 0.740940\n","\n","Training set: Average loss: 0.8527\n","Training set: Average Pixel Acc: 0.9393\n","Train Epoch: 48 [8/63 (14%)]\tLoss: 0.783404\n","\n","Training set: Average loss: 0.8403\n","Training set: Average Pixel Acc: 0.9210\n","Train Epoch: 48 [8/63 (14%)]\tLoss: 0.355802\n","\n","Training set: Average loss: 0.3260\n","Training set: Average Acc: 0.9643\n","Validation Set: Dice Score  0.8156096567130406\n","Train Epoch: 49 [8/63 (14%)]\tLoss: 0.786530\n","\n","Training set: Average loss: 0.8434\n","Training set: Average Pixel Acc: 0.9138\n","Train Epoch: 49 [8/63 (14%)]\tLoss: 0.729518\n","\n","Training set: Average loss: 0.8264\n","Training set: Average Pixel Acc: 0.9082\n","Train Epoch: 49 [8/63 (14%)]\tLoss: 0.281160\n","\n","Training set: Average loss: 0.3468\n","Training set: Average Acc: 0.9554\n","Validation Set: Dice Score  0.7958964318861013\n","Train Epoch: 50 [8/63 (14%)]\tLoss: 0.860835\n","\n","Training set: Average loss: 0.9057\n","Training set: Average Pixel Acc: 0.9112\n","Train Epoch: 50 [8/63 (14%)]\tLoss: 0.801476\n","\n","Training set: Average loss: 0.8475\n","Training set: Average Pixel Acc: 0.9376\n","Train Epoch: 50 [8/63 (14%)]\tLoss: 0.291490\n","\n","Training set: Average loss: 0.2902\n","Training set: Average Acc: 0.9821\n","Validation Set: Dice Score  0.8600493578559479\n"]}],"source":["_=get_GAN_model('CDNN','ViT')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O1oJ-jVLMqkv"},"outputs":[],"source":["for seg_name in segmentation_models:\n","    _=get_GAN_model(seg_name,'CNN')"]},{"cell_type":"markdown","metadata":{"id":"zcf26HbVuhMl"},"source":["# Evaluating GAN models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OgSgHcSTumHL"},"outputs":[],"source":["for seg_name in segmentation_models:\n","    for dis_name in discriminators:\n","        print('Segmentation model: ',seg_name)\n","        print('Discriminator: ',dis_name)\n","        (seg_net,_),_=get_GAN_model(seg_name,dis_name)\n","        evaluate(seg_net,test_dataloader)\n","        print()\n","        del seg_net\n","    print()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["uvKq4JtCynM5","tbb_b5ThzUDS","PVy6moDS7n1Z","8FQqyojwWEX1","zXkpp5CH22uK","hswKirdg3QBU","zcf26HbVuhMl"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}